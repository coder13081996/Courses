{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = x[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "# 784 here depicts the 28*28 pixels used for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets us try printing an image using matplotlib (this array contains shades of grey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_digit = x[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get an image we need to reshape the array into 28*28 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_digit_image = random_digit.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(random_digit_image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a testing and training dataset\n",
    "x_train, x_test, y_train, y_test = x[:20000], x[20000:], y[:20000], y[20000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Shuffling the training data set to prevent bias in the dataset (to try this for time series data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index = np.random.permutation(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### First we try training a binary classifier (whether it is a 3 or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '6', '2', ..., '3', '2', '1'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_3 = (y_train == '3') #true for all y == 3 and false otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using stochastic gradient descent for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This classifier has the advantage of being capable of handling very large datasets efficiently.\n",
    "# This is in part because SGD deals with training instances independently, one at a time\n",
    "# (which also makes SGD well suited for online learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(x_train, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([random_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking models performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring performance of a classifier is lot tougher than measuring for a regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Measuring accuracy using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhara\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9254537273136343\n",
      "0.9605519724013799\n",
      "0.963996399639964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "for train_index, test_index in skfolds.split(x_train, y_train_3):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    x_train_folds = x_train[train_index]\n",
    "    y_train_folds = (y_train_3[train_index])\n",
    "    x_test_fold = x_train[test_index]\n",
    "    y_test_fold = (y_train_3[test_index])\n",
    "    clone_clf.fit(x_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(x_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct / len(y_pred))\n",
    "    \n",
    "# The StratifiedKFold class performs stratified sampling to produce folds that contain a representative ratio of each class.\n",
    "# At each iteration the code creates a clone of the classifier, trains that clone on the training folds, and makes\n",
    "# predictions on the test fold. Then it counts the number of correct predictions and outputs the ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy is generally not the preferred performance measure for classifiers, especially when you are dealing with skewed \n",
    "# datasets (i.e., when some classes are much more frequent than others).\n",
    "\n",
    "# For eg. if you predict that an image is not a 3 it shows above 90% accuracy even with a faulty classifier.\n",
    "# because the data for non 3 is 90% true anyways, so even if its a faulty classifier it will correct 90% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To know how many times the classifier got confused and gave the wrong output\n",
    "\n",
    "# To check this on the above dataset (we try not to do this exercise on the test dataset as we want to save it for the \n",
    "# final classifer)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, x_train, y_train_3, cv=3)\n",
    "\n",
    "# performs K-fold cross-validation, but instead of returning the evaluation scores, it returns the predictions made on each test\n",
    "# fold. This means that you get a clean prediction for each instance in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17219,   705],\n",
       "       [  295,  1781]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_3, y_train_pred)\n",
    "\n",
    "# each row represents an actual class whereas each column represent a predicted class\n",
    "# [1,1] are the true negatives (non 3's correctly classified as non 3's)\n",
    "# [2,2] are the true positives (3's correctly classifies as 3's)\n",
    "# [1,2] are wrongly classified as 3's and are called false positives\n",
    "# [2,1] are wrongly classifies as non 3's called false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision = TP/(TP + FP)\n",
    "# if the number of predictions to be made for the true case are very less then the value for precision will be very high.\n",
    "# To avoid that we use recall also called sensitivity or true positive rate\n",
    "\n",
    "# recall = TP/(TP + FN)\n",
    "# the ratio of positive instances that are correctly detected by the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7164119066773934"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train_3, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8578998073217726"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_3, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So whenever it claims that an image is 3 it is correct only 80% of the time and also it is only able to detect 77% of the 3's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is easier to combine these two metrics and give them a combined score called as F1 score which is the harmonic mean of \n",
    "# precision and recall\n",
    "\n",
    "# F1 = 2/(1/precision + 1/recall)\n",
    "# F1 = TP/(TP + ((FN + FP)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7807978956597983"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_3, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The F1 score favors classifiers that have similar precision and recall.\n",
    "# That does not mean your bussiness requires both of them.\n",
    "\n",
    "# For example, if you trained a classifier to detect videos that are safe for kids, you would probably prefer a classifier\n",
    "# that rejects many good videos (low recall) but keeps only safe ones (high precision), rather than a classifier that has a\n",
    "# much higher recall but lets a few really bad videos show up in your product (in such cases, you may even want to add a \n",
    "# human pipeline to check the classifierâ€™s video selection).\n",
    "\n",
    "# On the other hand, suppose you train a classifier to detect shoplifters on surveillance images: it is probably fine if \n",
    "# your classifier has only 30% precision as long as it has 99% recall (sure, the security guards will get a few false\n",
    "# alerts, but almost all shoplifters will get caught)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision/ Recall Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Increasing precision reduces recall and vice versa\n",
    "\n",
    "\n",
    "<img src=\"notes_images/precision_recall_tradeoff.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilabel Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multioutput Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmem(total=8424574976, available=2006872064, percent=76.2, used=6417702912, free=2006872064)\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "print(psutil.virtual_memory())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 32-bit",
   "language": "python",
   "name": "python37432bitc89f6135340549e6a9537bdf4b44922a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
